{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d6f903",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install psycopg2-binary sqlalchemy pyarrow pandas requests\n",
    "import os\n",
    "from psycopg2.extras import execute_values\n",
    "import os, csv\n",
    "import time\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import tempfile\n",
    "from urllib.request import urlretrieve\n",
    "from pyspark.sql.functions import lit, current_timestamp\n",
    "import time\n",
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, current_timestamp, when, unix_timestamp, abs as spark_abs\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType, TimestampType\n",
    "PG_HOST = os.getenv('PG_HOST')\n",
    "PG_PORT = int(os.getenv('PG_PORT'))\n",
    "PG_DB = os.getenv('PG_DB')\n",
    "PG_USER = os.getenv('PG_USER')\n",
    "PG_PASSWORD = os.getenv('PG_PASSWORD')\n",
    "PG_SCHEMA_RAW = os.getenv('PG_SCHEMA_RAW')\n",
    "PG_SCHEMA_ANALYTICS = os.getenv('PG_SCHEMA_ANALYTICS')\n",
    "CHUNK_SIZE = int(os.getenv('CHUNK_SIZE', '1000000'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a39d56ba-c8ff-44ac-b533-8775228dc322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo de auditoría listo: /home/jovyan/auditoria/audit_ingesta.csv\n"
     ]
    }
   ],
   "source": [
    "AUDIT_DIR = \"/home/jovyan/auditoria\"\n",
    "os.makedirs(AUDIT_DIR, exist_ok=True)  # crea la carpeta si no existe\n",
    "\n",
    "AUDIT_CSV = os.path.join(AUDIT_DIR, \"audit_ingesta.csv\")\n",
    "\n",
    "# Crear el CSV si no existe\n",
    "if not os.path.exists(AUDIT_CSV):\n",
    "    with open(AUDIT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        wr = csv.writer(f)\n",
    "        wr.writerow([\"service\", \"year\", \"month\", \"rows\", \"status \",\"run_tag\", \"ts_utc\", \"error\"])\n",
    "\n",
    "def _audit_rows_set(status_filter=None):\n",
    "    \"\"\"\n",
    "    Devuelve un set de (service, year, month) ya registrados.\n",
    "    Si status_filter es una lista (p.ej. [\"OK\",\"SKIPPED\"]), filtra por esos estados.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(AUDIT_CSV):\n",
    "        return set()\n",
    "    df = pd.read_csv(AUDIT_CSV, dtype={\"service\": str, \"year\": int, \"month\": int, \"status\": str})\n",
    "    if status_filter:\n",
    "        df = df[df[\"status\"].isin(status_filter)]\n",
    "    return set(zip(df[\"service\"], df[\"year\"], df[\"month\"]))\n",
    "\n",
    "def is_already_loaded_csv(service: str, year: int, month: int) -> bool:\n",
    "    \"\"\"True si ya se registró como OK (cargado) en el CSV.\"\"\"\n",
    "    loaded = _audit_rows_set(status_filter=[\"OK\"])\n",
    "    return (service, year, month) in loaded\n",
    "\n",
    "def mark_audit_csv(service: str, year: int, month: int, status: str,\n",
    "                   rows: int = 0, run_tag: str = \"\", error: str = \"\"):\n",
    "    \"\"\"Agrega una fila de auditoría al CSV.\"\"\"\n",
    "    with open(AUDIT_CSV, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        wr = csv.writer(f)\n",
    "        wr.writerow([service, year, month, status, rows, run_tag,\n",
    "                     datetime.utcnow().isoformat(), error[:500]])\n",
    "\n",
    "print(f\"Archivo de auditoría listo: {AUDIT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f617037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración cargada:\n",
      "  - Postgres: root@postgres:5432/nyc_taxi\n",
      "  - Schema RAW: raw\n",
      "  - Años: 2015-2025\n",
      "  - Servicios: ['yellow', 'green']\n",
      "  - RUN_TAG: ingesta_20251110_172710\n"
     ]
    }
   ],
   "source": [
    "# Cargar variables de ambiente\n",
    "PG_HOST = os.getenv('PG_HOST', 'postgres')\n",
    "PG_PORT = os.getenv('PG_PORT', '5432')\n",
    "PG_DB = os.getenv('PG_DB', 'nyc_tlc')\n",
    "PG_USER = os.getenv('PG_USER', 'postgres')\n",
    "PG_PASSWORD = os.getenv('PG_PASSWORD', 'postgres')\n",
    "PG_SCHEMA_RAW = os.getenv('PG_SCHEMA_RAW', 'raw')\n",
    "\n",
    "# Parámetros de ingesta\n",
    "YEARS = list(range(2015, 2026))  \n",
    "MONTHS = list(range(1, 13))      \n",
    "SERVICES = ['yellow', 'green']   \n",
    "RUN_TAG = os.getenv('RUN_TAG', f\"ingesta_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}\")\n",
    "\n",
    "# URL base para los archivos Parquet de NYC TLC\n",
    "BASE_URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data\"\n",
    "\n",
    "print(\"Configuración cargada:\")\n",
    "print(f\"  - Postgres: {PG_USER}@{PG_HOST}:{PG_PORT}/{PG_DB}\")\n",
    "print(f\"  - Schema RAW: {PG_SCHEMA_RAW}\")\n",
    "print(f\"  - Años: {YEARS[0]}-{YEARS[-1]}\")\n",
    "print(f\"  - Servicios: {SERVICES}\")\n",
    "print(f\"  - RUN_TAG: {RUN_TAG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a753e767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark 3.5.0 inicializado correctamente\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"NYC_TLC_Ingesta_Raw\")\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.6.0\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.executor.memory\", \"4g\")\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "    .config(\"spark.driver.extraClassPath\", \"/usr/local/spark/jars/postgresql-42.6.0.jar\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(f\"Spark {spark.version} inicializado correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ac27e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funciones de utilidad cargadas correctamente\n"
     ]
    }
   ],
   "source": [
    "def compose_url(service: str, year: int, month: int) -> str:\n",
    "    filename = f\"{service}_tripdata_{year}-{month:02d}.parquet\"\n",
    "    return f\"{BASE_URL}/{filename}\"\n",
    "\n",
    "def download_to_temp(url: str) -> str:\n",
    "    temp_dir = tempfile.gettempdir()\n",
    "    filename = url.split('/')[-1]\n",
    "    local_path = os.path.join(temp_dir, filename)\n",
    "    if not os.path.exists(local_path):\n",
    "        print(f\"  Descargando: {filename}...\", end=\" \")\n",
    "        urlretrieve(url, local_path)\n",
    "        print(\"OK\")\n",
    "    else:\n",
    "        print(f\"  Usando caché local: {filename}\")\n",
    "    return local_path\n",
    "\n",
    "def get_postgres_jdbc_url() -> str:\n",
    "    return f\"jdbc:postgresql://{PG_HOST}:{PG_PORT}/{PG_DB}\"\n",
    "\n",
    "def get_postgres_properties() -> dict:\n",
    "    return {\n",
    "        \"user\": PG_USER,\n",
    "        \"password\": PG_PASSWORD,\n",
    "        \"driver\": \"org.postgresql.Driver\"\n",
    "    }\n",
    "\n",
    "print(\"Funciones de utilidad cargadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c96f8349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función de estandarización cargada\n"
     ]
    }
   ],
   "source": [
    "def standardize_columns(df, service: str):\n",
    "    column_mapping = {\n",
    "        'VendorID': 'VendorID',\n",
    "        'RatecodeID': 'RatecodeID',\n",
    "        'PULocationID': 'PULocationID',\n",
    "        'DOLocationID': 'DOLocationID',\n",
    "        'passenger_count': 'passenger_count',\n",
    "        'trip_distance': 'trip_distance',\n",
    "        'fare_amount': 'fare_amount',\n",
    "        'extra': 'extra',\n",
    "        'mta_tax': 'mta_tax',\n",
    "        'tip_amount': 'tip_amount',\n",
    "        'tolls_amount': 'tolls_amount',\n",
    "        'improvement_surcharge': 'improvement_surcharge',\n",
    "        'total_amount': 'total_amount',\n",
    "        'payment_type': 'payment_type',\n",
    "        'congestion_surcharge': 'congestion_surcharge',\n",
    "        'airport_fee': 'airport_fee',\n",
    "        'store_and_fwd_flag': 'store_and_fwd_flag',\n",
    "        'CBD_CONGESTION_FEE': 'CBD_CONGESTION_FEE',\n",
    "        'cbd_congestion_fee': 'cbd_congestion_fee',\n",
    "\n",
    "    }\n",
    "    for old_name, new_name in column_mapping.items():\n",
    "        if old_name in df.columns and old_name != new_name:\n",
    "            df = df.withColumnRenamed(old_name, new_name)\n",
    "    if service == 'yellow':\n",
    "        if 'tpep_pickup_datetime' in df.columns:\n",
    "            df = df.withColumn('tpep_pickup_datetime', col('tpep_pickup_datetime').cast(TimestampType()))\n",
    "        if 'tpep_dropoff_datetime' in df.columns:\n",
    "            df = df.withColumn('tpep_dropoff_datetime', col('tpep_dropoff_datetime').cast(TimestampType()))\n",
    "    elif service == 'green':\n",
    "        if 'lpep_pickup_datetime' in df.columns:\n",
    "            df = df.withColumn('lpep_pickup_datetime', col('lpep_pickup_datetime').cast(TimestampType()))\n",
    "        if 'lpep_dropoff_datetime' in df.columns:\n",
    "            df = df.withColumn('lpep_dropoff_datetime', col('lpep_dropoff_datetime').cast(TimestampType()))\n",
    "        if 'trip_type' in df.columns:\n",
    "            df = df.withColumn('trip_type', col('trip_type').cast(IntegerType()))\n",
    "    numeric_int_cols = ['VendorID', 'RatecodeID', 'PULocationID', 'DOLocationID', 'passenger_count', 'payment_type']\n",
    "    numeric_double_cols = ['trip_distance', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
    "                           'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'airport_fee', 'CBD_CONGESTION_FEE']\n",
    "    for col_name in numeric_int_cols:\n",
    "        if col_name in df.columns:\n",
    "            df = df.withColumn(col_name, col(col_name).cast(IntegerType()))\n",
    "    for col_name in numeric_double_cols:\n",
    "        if col_name in df.columns:\n",
    "            df = df.withColumn(col_name, col(col_name).cast(DoubleType()))\n",
    "    if 'store_and_fwd_flag' in df.columns:\n",
    "        df = df.withColumn('store_and_fwd_flag', col('store_and_fwd_flag').cast(StringType()))\n",
    "    if 'CBD_CONGESTION_FEE' in df.columns and 'cbd_congestion_fee' not in df.columns:\n",
    "        df = df.withColumnRenamed('CBD_CONGESTION_FEE', 'cbd_congestion_fee')\n",
    "    if 'cbd_congestion_fee' not in df.columns:\n",
    "        df = df.withColumn('cbd_congestion_fee', lit(None).cast(DoubleType()))\n",
    "    return df\n",
    "\n",
    "print(\"Función de estandarización cargada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f768343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función de metadatos cargada\n"
     ]
    }
   ],
   "source": [
    "def add_metadata(df, year: int, month: int, run_tag: str):\n",
    "    \"\"\"Agrega columnas de metadatos para trazabilidad de la ingesta.\"\"\"\n",
    "    return (\n",
    "        df\n",
    "        .withColumn('run_tag', lit(run_tag))\n",
    "        .withColumn('source_year', lit(year))\n",
    "        .withColumn('source_month', lit(month))\n",
    "        .withColumn('ingested_at_utc', current_timestamp())\n",
    "    )\n",
    "\n",
    "print(\"Función de metadatos cargada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27e036e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Función de escritura a Postgres cargada\n"
     ]
    }
   ],
   "source": [
    "def write_batch(df, fact_table: str, mode: str = \"append\", writers: int = 4, batchsize: int = 5000):\n",
    "    df_to_write = df.coalesce(writers) \n",
    "\n",
    "    (df_to_write.write\n",
    "        .format(\"jdbc\")\n",
    "        .option(\"url\", get_postgres_jdbc_url())\n",
    "        .option(\"dbtable\", fact_table)\n",
    "        .option(\"user\", PG_USER)\n",
    "        .option(\"password\", PG_PASSWORD)\n",
    "        .option(\"driver\", \"org.postgresql.Driver\")\n",
    "        .option(\"batchsize\", str(batchsize))   \n",
    "        .mode(mode)\n",
    "        .save()\n",
    "    )\n",
    "\n",
    "print(\"Función de escritura a Postgres cargada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c511bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esquemas 'raw' y 'analytics' verificados/creados\n"
     ]
    }
   ],
   "source": [
    "def create_schemas():\n",
    "    \"\"\"Crea los esquemas raw y analytics si no existen.\"\"\"\n",
    "    conn = psycopg2.connect(\n",
    "        host=PG_HOST,\n",
    "        port=PG_PORT,\n",
    "        database=PG_DB,\n",
    "        user=PG_USER,\n",
    "        password=PG_PASSWORD\n",
    "    )\n",
    "    conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"CREATE SCHEMA IF NOT EXISTS {PG_SCHEMA_RAW};\")\n",
    "    cursor.execute(\"CREATE SCHEMA IF NOT EXISTS analytics;\")\n",
    "    print(f\"Esquemas '{PG_SCHEMA_RAW}' y 'analytics' verificados/creados\")\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "# Ejecutar creación de esquemas\n",
    "create_schemas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5db6bf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "» Inicio de proceso\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "SERVICIO: YELLOW → raw.yellow_taxi_trip\n",
      "================================================================================\n",
      "\n",
      "[2015-01] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-03] Procesando yellow...\n",
      "  Usando caché local: yellow_tripdata_2015-03.parquet\n",
      "    Filas descargadas: 13,342,951\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 13,342,951 filas insertadas en 209.6s\n",
      "\n",
      "[2015-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-01] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-03] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-01] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-03] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-01] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-03] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-01] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-03] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-01] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-03] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-01] Procesando yellow...\n",
      "  Usando caché local: yellow_tripdata_2021-01.parquet\n",
      "    Filas descargadas: 1,369,769\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 1,369,769 filas insertadas en 20.7s\n",
      "\n",
      "[2021-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-03] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-01] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-03] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-01] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-03] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-01] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-03] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2025-01] Procesando yellow...\n",
      "  Usando caché local: yellow_tripdata_2025-01.parquet\n",
      "    Filas descargadas: 3,475,226\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,475,226 filas insertadas en 32.8s\n",
      "\n",
      "[2025-02] Procesando yellow...\n",
      "  Usando caché local: yellow_tripdata_2025-02.parquet\n",
      "    Filas descargadas: 3,577,543\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,577,543 filas insertadas en 41.0s\n",
      "\n",
      "[2025-03] Procesando yellow...\n",
      "  Usando caché local: yellow_tripdata_2025-03.parquet\n",
      "    Filas descargadas: 4,145,257\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 4,145,257 filas insertadas en 36.0s\n",
      "\n",
      "[2025-04] Procesando yellow...\n",
      "  Usando caché local: yellow_tripdata_2025-04.parquet\n",
      "    Filas descargadas: 3,970,553\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,970,553 filas insertadas en 36.5s\n",
      "\n",
      "[2025-05] Procesando yellow...\n",
      "  Usando caché local: yellow_tripdata_2025-05.parquet\n",
      "    Filas descargadas: 4,591,845\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 4,591,845 filas insertadas en 38.6s\n",
      "\n",
      "[2025-06] Procesando yellow...\n",
      "  Usando caché local: yellow_tripdata_2025-06.parquet\n",
      "    Filas descargadas: 4,322,960\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 4,322,960 filas insertadas en 37.8s\n",
      "\n",
      "[2025-07] Procesando yellow...\n",
      "  Usando caché local: yellow_tripdata_2025-07.parquet\n",
      "    Filas descargadas: 3,898,963\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,898,963 filas insertadas en 34.7s\n",
      "\n",
      "[2025-08] Procesando yellow...\n",
      "  Usando caché local: yellow_tripdata_2025-08.parquet\n",
      "    Filas descargadas: 3,574,091\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 3,574,091 filas insertadas en 44.6s\n",
      "\n",
      "[2025-09] Procesando yellow...\n",
      "  Usando caché local: yellow_tripdata_2025-09.parquet\n",
      "    Filas descargadas: 4,251,015\n",
      "    Escribiendo a raw.yellow_taxi_trip... OK\n",
      "    [OK] 4,251,015 filas insertadas en 35.6s\n",
      "\n",
      "[2025-10] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2025-10.parquet...     [ERROR] HTTP Error 403: Forbidden\n",
      "\n",
      "[2025-11] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2025-11.parquet...     [ERROR] HTTP Error 403: Forbidden\n",
      "\n",
      "[2025-12] Procesando yellow...\n",
      "  Descargando: yellow_tripdata_2025-12.parquet...     [ERROR] HTTP Error 403: Forbidden\n",
      "\n",
      "\n",
      "================================================================================\n",
      "» Resumen de ejecución del servicio\n",
      "  Filas insertadas: 50,520,173\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "SERVICIO: GREEN → raw.green_taxi_trip\n",
      "================================================================================\n",
      "\n",
      "[2015-01] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-03] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2015-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-01] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-03] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2016-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-01] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-03] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2017-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-01] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-03] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2018-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-01] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-03] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2019-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-01] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-03] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2020-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-01] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-03] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2021-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-01] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-03] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2022-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-01] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-03] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2023-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-01] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-02] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-03] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-04] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-05] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-06] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-07] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-08] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-09] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-10] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-11] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2024-12] Ya marcado como OK en auditoría CSV → saltando\n",
      "[2025-01] Procesando green...\n",
      "  Usando caché local: green_tripdata_2025-01.parquet\n",
      "    Filas descargadas: 48,326\n",
      "    Escribiendo a raw.green_taxi_trip... OK\n",
      "    [OK] 48,326 filas insertadas en 3.2s\n",
      "\n",
      "[2025-02] Procesando green...\n",
      "  Usando caché local: green_tripdata_2025-02.parquet\n",
      "    Filas descargadas: 46,621\n",
      "    Escribiendo a raw.green_taxi_trip... OK\n",
      "    [OK] 46,621 filas insertadas en 2.0s\n",
      "\n",
      "[2025-03] Procesando green...\n",
      "  Usando caché local: green_tripdata_2025-03.parquet\n",
      "    Filas descargadas: 51,539\n",
      "    Escribiendo a raw.green_taxi_trip... OK\n",
      "    [OK] 51,539 filas insertadas en 1.9s\n",
      "\n",
      "[2025-04] Procesando green...\n",
      "  Usando caché local: green_tripdata_2025-04.parquet\n",
      "    Filas descargadas: 52,132\n",
      "    Escribiendo a raw.green_taxi_trip... OK\n",
      "    [OK] 52,132 filas insertadas en 1.9s\n",
      "\n",
      "[2025-05] Procesando green...\n",
      "  Usando caché local: green_tripdata_2025-05.parquet\n",
      "    Filas descargadas: 55,399\n",
      "    Escribiendo a raw.green_taxi_trip... OK\n",
      "    [OK] 55,399 filas insertadas en 1.5s\n",
      "\n",
      "[2025-06] Procesando green...\n",
      "  Usando caché local: green_tripdata_2025-06.parquet\n",
      "    Filas descargadas: 49,390\n",
      "    Escribiendo a raw.green_taxi_trip... OK\n",
      "    [OK] 49,390 filas insertadas en 1.7s\n",
      "\n",
      "[2025-07] Procesando green...\n",
      "  Usando caché local: green_tripdata_2025-07.parquet\n",
      "    Filas descargadas: 48,205\n",
      "    Escribiendo a raw.green_taxi_trip... OK\n",
      "    [OK] 48,205 filas insertadas en 1.3s\n",
      "\n",
      "[2025-08] Procesando green...\n",
      "  Usando caché local: green_tripdata_2025-08.parquet\n",
      "    Filas descargadas: 46,306\n",
      "    Escribiendo a raw.green_taxi_trip... OK\n",
      "    [OK] 46,306 filas insertadas en 1.5s\n",
      "\n",
      "[2025-09] Procesando green...\n",
      "  Usando caché local: green_tripdata_2025-09.parquet\n",
      "    Filas descargadas: 48,893\n",
      "    Escribiendo a raw.green_taxi_trip... OK\n",
      "    [OK] 48,893 filas insertadas en 1.2s\n",
      "\n",
      "[2025-10] Procesando green...\n",
      "  Descargando: green_tripdata_2025-10.parquet...     [ERROR] HTTP Error 403: Forbidden\n",
      "\n",
      "[2025-11] Procesando green...\n",
      "  Descargando: green_tripdata_2025-11.parquet...     [ERROR] HTTP Error 403: Forbidden\n",
      "\n",
      "[2025-12] Procesando green...\n",
      "  Descargando: green_tripdata_2025-12.parquet...     [ERROR] HTTP Error 403: Forbidden\n",
      "\n",
      "\n",
      "================================================================================\n",
      "» Resumen de ejecución del servicio\n",
      "  Filas insertadas: 446,811\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "» RESUMEN GLOBAL DE EJECUCIÓN\n",
      "================================================================================\n",
      "Total filas insertadas: 50,966,984\n",
      "Total errores: 6\n",
      "RUN_TAG: ingesta_20251110_172710\n",
      "================================================================================\n",
      "\n",
      "Log de auditoría cargado en variable 'log_df'\n"
     ]
    }
   ],
   "source": [
    "total_rows = 0\n",
    "total_errors = 0\n",
    "ingestion_log = []\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"» Inicio de proceso\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for service in SERVICES:\n",
    "    table = f\"{PG_SCHEMA_RAW}.{service}_taxi_trip\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SERVICIO: {service.upper()} → {table}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "    service_rows = 0\n",
    "\n",
    "    for y in YEARS:\n",
    "        for m in MONTHS:\n",
    "\n",
    "            # 0) Verificar si ya fue cargado (CSV)\n",
    "            if is_already_loaded_csv(service, y, m):\n",
    "                print(f\"[{y}-{m:02d}] Ya marcado como OK en auditoría CSV → saltando\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                t0 = time.time()\n",
    "                print(f\"[{y}-{m:02d}] Procesando {service}...\")\n",
    "\n",
    "                # 1) Descargar y leer Parquet\n",
    "                tmp_path = download_to_temp(compose_url(service, y, m))\n",
    "                raw_df = spark.read.parquet(tmp_path)\n",
    "                raw_count = raw_df.count()\n",
    "                print(f\"    Filas descargadas: {raw_count:,}\")\n",
    "\n",
    "                # 2) Estandarizar columnas\n",
    "                df = standardize_columns(raw_df, service)\n",
    "\n",
    "                # 3) (sin limpieza) usar el DF tal cual\n",
    "                df_final = add_metadata(df, y, m, RUN_TAG).withColumn(\"service_type\", lit(service))\n",
    "                clean_count = raw_count\n",
    "\n",
    "                # 4) Escribir a Postgres\n",
    "                print(f\"    Escribiendo a {table}...\", end=\" \")\n",
    "                write_batch(df_final, table, mode=\"append\", writers=4, batchsize=5000)\n",
    "                print(\"OK\")\n",
    "\n",
    "                # 5) Estadísticas\n",
    "                service_rows += clean_count\n",
    "                total_rows += clean_count\n",
    "                dt = time.time() - t0\n",
    "\n",
    "                print(f\"    [OK] {clean_count:,} filas insertadas en {dt:.1f}s\\n\")\n",
    "\n",
    "                # 6) Marcar auditoría como OK\n",
    "                mark_audit_csv(service, y, m, status=\"OK\", rows=clean_count, run_tag=RUN_TAG)\n",
    "\n",
    "            except Exception as e:\n",
    "                total_errors += 1\n",
    "                print(f\"    [ERROR] {e}\\n\")\n",
    "                mark_audit_csv(service, y, m, status=\"ERROR\", rows=0, run_tag=RUN_TAG, error=str(e))\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"» Resumen de ejecución del servicio\")\n",
    "    print(f\"  Filas insertadas: {service_rows:,}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "# RESUMEN \n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"» RESUMEN GLOBAL DE EJECUCIÓN\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total filas insertadas: {total_rows:,}\")\n",
    "print(f\"Total errores: {total_errors}\")\n",
    "print(f\"RUN_TAG: {RUN_TAG}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "log_df = pd.read_csv(AUDIT_CSV)\n",
    "print(\"\\nLog de auditoría cargado en variable 'log_df'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54a2304f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    service  year  month      rows status                  run_tag  \\\n",
      "0    yellow  2015      1  12741035     OK  ingesta_20251110_043934   \n",
      "1    yellow  2015      2  12442394     OK  ingesta_20251110_043934   \n",
      "2    yellow  2015      4  13063758     OK  ingesta_20251110_043934   \n",
      "3    yellow  2015      5  13157677     OK  ingesta_20251110_043934   \n",
      "4    yellow  2015      6  12324936     OK  ingesta_20251110_043934   \n",
      "..      ...   ...    ...       ...    ...                      ...   \n",
      "285   green  2025      8        OK  46306  ingesta_20251110_172710   \n",
      "286   green  2025      9        OK  48893  ingesta_20251110_172710   \n",
      "287   green  2025     10     ERROR      0  ingesta_20251110_172710   \n",
      "288   green  2025     11     ERROR      0  ingesta_20251110_172710   \n",
      "289   green  2025     12     ERROR      0  ingesta_20251110_172710   \n",
      "\n",
      "                         ts_utc                      error  \n",
      "0          2025-11-10T04:39:37Z                        NaN  \n",
      "1          2025-11-10T04:42:59Z                        NaN  \n",
      "2          2025-11-10T04:46:14Z                        NaN  \n",
      "3          2025-11-10T04:49:46Z                        NaN  \n",
      "4          2025-11-10T04:53:40Z                        NaN  \n",
      "..                          ...                        ...  \n",
      "285  2025-11-10T17:36:55.668114                        NaN  \n",
      "286  2025-11-10T17:36:56.900804                        NaN  \n",
      "287  2025-11-10T17:36:57.456102  HTTP Error 403: Forbidden  \n",
      "288  2025-11-10T17:36:57.869743  HTTP Error 403: Forbidden  \n",
      "289  2025-11-10T17:36:58.275956  HTTP Error 403: Forbidden  \n",
      "\n",
      "[290 rows x 8 columns]\n",
      "\n",
      "=== RESUMEN POR SERVICIO Y ESTADO ===\n",
      "service   status  N_Meses Total_Filas\n",
      "  green        0       15           0\n",
      "  green    46306        1           0\n",
      "  green    46621        1           0\n",
      "  green    48205        1           0\n",
      "  green    48326        1           0\n",
      "  green    48893        1           0\n",
      "  green    49390        1           0\n",
      "  green    51539        1           0\n",
      "  green    52132        1           0\n",
      "  green    55399        1           0\n",
      "  green       OK      120  67,647,679\n",
      " yellow        0       17           0\n",
      " yellow 13342951        1           0\n",
      " yellow  1369769        1           0\n",
      " yellow  3475226        1           0\n",
      " yellow  3574091        1           0\n",
      " yellow  3577543        1           0\n",
      " yellow  3898963        1           0\n",
      " yellow  3970553        1           0\n",
      " yellow  4145257        1           0\n",
      " yellow  4251015        1           0\n",
      " yellow  4322960        1           0\n",
      " yellow  4591845        1           0\n",
      " yellow       OK      118 738,117,918\n"
     ]
    }
   ],
   "source": [
    "print(log_df)\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1) Copia segura y normaliza tipos ---\n",
    "df = log_df.copy()\n",
    "\n",
    "# Asegura que year, month, rows sean numéricos\n",
    "for c in [\"year\", \"month\", \"rows\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# --- 2) Resumen por servicio/estado ---\n",
    "summary = (\n",
    "    df.groupby([\"service\", \"status\"])[\"rows\"]\n",
    "      .agg(N_Meses=\"count\", Total_Filas=\"sum\")\n",
    "      .reset_index()\n",
    "      .sort_values([\"service\", \"status\"])\n",
    ")\n",
    "\n",
    "# Formato amigable (separador de miles)\n",
    "summary_fmt = summary.copy()\n",
    "summary_fmt[\"Total_Filas\"] = summary_fmt[\"Total_Filas\"].map(lambda v: f\"{v:,}\")\n",
    "\n",
    "print(\"\\n=== RESUMEN POR SERVICIO Y ESTADO ===\")\n",
    "try:\n",
    "    # bonito si tienes tabulate instalado\n",
    "    from tabulate import tabulate\n",
    "    print(tabulate(summary_fmt, headers=\"keys\", tablefmt=\"github\", showindex=False))\n",
    "except Exception:\n",
    "    # fallback estándar\n",
    "    print(summary_fmt.to_string(index=False))\n",
    "\n",
    "# --- 3) Porcentaje de errores por servicio ---\n",
    "pivot = (\n",
    "    summary.pivot(index=\"service\", columns=\"status\", values=\"N_Meses\")\n",
    "           .fillna(0)\n",
    ")\n",
    "pivot[\"Total_Meses\"] = pivot.sum(axis=1)\n",
    "pivot[\"% Error\"] = (pivot.get(\"ERROR\", 0) / pivot[\"Total_Meses\"] * 100).round(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c3076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL del archivo taxi_zone_lookup\n",
    "ZONE_LOOKUP_URL = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv\"\n",
    "\n",
    "print(\"Descargando Taxi Zone Lookup...\")\n",
    "try:\n",
    "    # Descargar CSV\n",
    "    temp_dir = tempfile.gettempdir()\n",
    "    zone_path = os.path.join(temp_dir, \"taxi_zone_lookup.csv\")\n",
    "    urlretrieve(ZONE_LOOKUP_URL, zone_path)\n",
    "\n",
    "    # Leer con Spark\n",
    "    zones_df = spark.read.csv(zone_path, header=True, inferSchema=True)\n",
    "\n",
    "    # Estandarizar nombres de columnas\n",
    "    zones_df = zones_df.toDF(*[c.lower().replace(' ', '_') for c in zones_df.columns])\n",
    "\n",
    "    # Agregar metadatos\n",
    "    zones_df = zones_df.withColumn('run_tag', lit(RUN_TAG)) \\\n",
    "                       .withColumn('ingested_at_utc', current_timestamp())\n",
    "\n",
    "    # Contar filas\n",
    "    zone_count = zones_df.count()\n",
    "    print(f\"Zonas cargadas: {zone_count}\")\n",
    "\n",
    "    # Escribir a Postgres (overwrite para mantener actualizado)\n",
    "    zones_table = f\"{PG_SCHEMA_RAW}.taxi_zone_lookup\"\n",
    "    write_batch(zones_df, zones_table, mode=\"overwrite\")\n",
    "\n",
    "    print(f\"Taxi Zone Lookup insertado en {zones_table}\")\n",
    "\n",
    "    # Mostrar preview\n",
    "    zones_df.show(10, truncate=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"[error] revisar detalle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf380c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VALIDACIÓN FINAL: Conteos en Postgres\n",
      "================================================================================\n",
      "\n",
      "raw.yellow_taxi_trip: 788,638,091 filas\n",
      "raw.green_taxi_trip: 68,094,490 filas\n",
      "raw.taxi_zone_lookup: 265 filas\n",
      "\n",
      "TOTAL TRIPS: 856,732,581 filas\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def get_table_count(fact_table: str) -> int:\n",
    "    \"\"\"Obtiene el conteo de filas de una tabla en Postgres.\"\"\"\n",
    "    jdbc_url = get_postgres_jdbc_url()\n",
    "    properties = get_postgres_properties()\n",
    "    query = f\"(SELECT COUNT(*) as count FROM {fact_table}) as subquery\"\n",
    "    df = spark.read.jdbc(url=jdbc_url, table=query, properties=properties)\n",
    "    return df.collect()[0]['count']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VALIDACIÓN FINAL: Conteos en Postgres\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    yellow_count = get_table_count(f\"{PG_SCHEMA_RAW}.yellow_taxi_trip\")\n",
    "    print(f\"\\n{PG_SCHEMA_RAW}.yellow_taxi_trip: {yellow_count:,} filas\")\n",
    "except Exception as e:\n",
    "    print(f\"Error leyendo yellow_taxi_trip: {e}\")\n",
    "    yellow_count = 0\n",
    "\n",
    "try:\n",
    "    green_count = get_table_count(f\"{PG_SCHEMA_RAW}.green_taxi_trip\")\n",
    "    print(f\"{PG_SCHEMA_RAW}.green_taxi_trip: {green_count:,} filas\")\n",
    "except Exception as e:\n",
    "    print(f\"Error leyendo green_taxi_trip: {e}\")\n",
    "    green_count = 0\n",
    "\n",
    "try:\n",
    "    zones_count = get_table_count(f\"{PG_SCHEMA_RAW}.taxi_zone_lookup\")\n",
    "    print(f\"{PG_SCHEMA_RAW}.taxi_zone_lookup: {zones_count:,} filas\")\n",
    "except Exception as e:\n",
    "    print(f\"Error leyendo taxi_zone_lookup: {e}\")\n",
    "    zones_count = 0\n",
    "\n",
    "print(f\"\\nTOTAL TRIPS: {yellow_count + green_count:,} filas\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
